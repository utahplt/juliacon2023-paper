% JuliaCon proceedings template
\documentclass{juliacon}
\setcounter{page}{1}
\usepackage{amsmath}
\usepackage{cleveref}
\usepackage{microtype}
\usepackage{pifont}

%% extra links:
%% - GPU Julia: https://cuda.juliagpu.org/stable/tutorials/introduction/
%% - GPU x2: https://nextjournal.com/sdanisch/julia-gpu-programming
%% - NaN vs missing https://discourse.julialang.org/t/is-there-any-reason-to-use-nan-instead-of-missing/84396

\begin{document}

% Misc typographical tweaks.
\setlength{\parindent}{10pt}
% \setmonofont{JuliaMono}[Extension = .ttf, Path = ./, UprightFont = *-Regular, ItalicFont = *-Italic]

\input{header}
\maketitle

\begin{abstract}
  Reliable numerical computations are central to scientific computing,
  but the floating-point arithmetic that enables large-scale models
  is fundamentally unreliable.
  Numeric exceptions are a common occurrence and can propagate through
  code, leading to flawed results.
  This paper presents FlowFPX, a toolkit for systematically debugging
  floating-point exceptions by recording their flow,
  coalescing exception contexts, and fuzzing in select locations.
  These tools help scientists discover when exceptions happen
  and track down their origin, smoothing the way to a reliable codebase.
\end{abstract}

\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\FlowFPX}{FlowFPX}
\newcommand{\GPUFPX}{GPU-FPX}
\newcommand{\FloatTracker}{FloatTracker}
\newcommand{\FT}{\FloatTracker}
\newcommand{\Fp}{Floating-point} % hyphen or no?
\newcommand{\fp}{floating-point} % hyphen or no?
\newcommand{\CSTG}{stack graph}
\newcommand{\CPP}{\code{C++}}
\newcommand{\Dendro}{\textsc{Dendro}}
\newcommand{\urlaccess}[2]{\url{#1}}
\newcommand{\Nan}{\code{NaN}}
\newcommand{\NaN}{\Nan}
\newcommand{\Inf}{\code{Inf}}
\newcommand{\zerowidth}[1]{\makebox[0pt][l]{#1}}
\newcommand{\zerocode}[1]{\zerowidth{\code{#1}}}
\newcommand{\genpropkill}{\emph{gen}-\emph{prop}-\emph{kill}}
\newcommand{\bigcheckmark}{\ding{51}}
\newcommand{\bigxmark}{\ding{53}}
\newcommand{\tblnext}{\(\Rightarrow\)}
\newcommand{\tblY}{\mbox{\bigcheckmark}}
\newcommand{\tblN}{\scalebox{0.8}{\bigxmark}}

\section{Introduction}

Reliable numeric computations are central to high-performance computing,
machine learning, and scientific applications.
Yet the \fp{} arithmetic that powers these computations is fundamentally
unreliable~(\cref{s:background}).
Exceptional values, such as Not a Number (\Nan{}) and infinity (\Inf{}),
can and often do arise thanks to culprits such as roundoff error,
catastrophic cancellation, singular matrices, and vanishing
derivatives~\cite{sdjmrstp-pc-2022,ddghlllprr-correctness-2022,gllprt-correctness-2021,fpchecker-reports,llg-soap-2022,bllmg-xloop-2022}.
Developers are responsible for guarding against exceptions, but this task
is difficult because many operations can generate and propagate exceptions.
Worst of all, operations such as less-than (\code{<}) can kill an exceptional value,
leaving no trace of the problem.
There is little tool support to assist in exception debugging,
thus (unsurprisingly) a quick GitHub search reports over 4,000 open issues
related to \NaN{} or \Inf{} exceptions~\cite{github-issues}.

This paper introduces \FlowFPX{}, a toolkit for debugging
\fp{} exceptions~(\cref{s:flowfpx})
that hase helped improve a variety of applications,
from ocean simulations to heat modes~(\cref{s:casestudies}):
\begin{itemize}
  \item
    The centerpiece of \FlowFPX{} is \FT{}, a dynamic analysis tool that
    selectively monitors for exceptions and fuzzes code for vulnerabilities.
  \item
    To visualize results, \FT{} adapts coalesced stack-trace graphs (CSTGs, or
    \CSTG{}s)~\cite{humphreySystematicDebuggingMethods2014}
    to summarize the program contexts that handled exceptional values.
  \item
    A companion tool \GPUFPX{}~\cite{llsflg-hpdc-2023} provides fine-grained insights for GPU kernels.
\end{itemize}


\section{Floating-Point Exception Primer}
\label{s:background}

\begin{figure}[t]\centering
  \includegraphics[trim=0 0 0 60,clip,width=0.95\columnwidth]{fig/real_vs_fp.png}
  \caption{Floats are spread across the real number line}
  \label{f:real-vs-fp}
\end{figure}

\Fp{} numbers use a finite number of bits to represent a spectrum of points along the real number line~(\cref{f:real-vs-fp}).
The implementation strategy is essentially scientific notation.
A \fp{} number packs a sign bit, an exponent, and a fraction part (also called the ``significand'' or ``mantissa'') into a bitstring.
Typical strings are 64 or 32 bits long, but 16-bit and 8-bit formats are on the rise~\cite{klowerLowprecisionClimateComputing2021,fp8}.
This representation supports very small and very large numbers in a narrow range of bits:

\begin{lstlisting}[language = Julia]
julia> prevfloat(typemax(Float64))
1.7976931348623157e308
julia> nextfloat(typemin(Float64))
-1.7976931348623157e308
\end{lstlisting}

The flip side is that most real numbers fall into the gaps between \fp{} numbers and must be rounded, which introduces error
and can lead to surprising results.
For example, adding the tiny Planck constant to the large Avogadro number results
in Avogadro's number after rounding:

\begin{lstlisting}[language = Julia]
julia> planck = 6.62607015e-34
6.62607015e-34
julia> avogadro = 6.02214076e23
6.02214076e23
julia> avogadro + planck == avogadro
true
\end{lstlisting}

This is an extreme example, but many operations on \fp{} numbers closer in magnitude induce a loss of accuracy.
Refer to the literature for more details, e.g.,~\cite{knuthArtComputerProgramming1997,torontoPracticallyAccurateFloatingPoint2014,mullerHandbookFloatingPointArithmetic2018}.


\subsection{Exceptions and Exceptional Values}
\label{s:exnvalue}

The IEEE~754 \fp{} standard~\cite{IEEEStandardBinary1985}
defines exceptions and exceptional values as the outcome of
operations that have ``no single universally acceptable result''~\cite{p-draft-1997}.
For example, dividing by zero and exceeding the \code{Float64} range
both lead to exceptions:

% julia> 2 / 0
% Inf
\begin{lstlisting}[language = Julia]
julia> 0 / 0
NaN
julia> avogadro^avogadro
Inf
julia> log(0)
-Inf
julia> Inf + NaN
NaN
\end{lstlisting}

IEEE~754 defers the question of how to handle such exceptions to application code.
It is up to developers to watch for \Nan{}, \Inf{}, and subnormal numbers (underflow)
and implement an appropriate repair.
This is no easy task, however, because of the approximations inherent to
floating point.
Even an apparently-safe division could result in a \Nan{} if its
denominator gets truncated to zero.
Some \Nan{}s might be spurious, others might be fatal, but in any event
anticipating the various exceptions is a burden.
All too often, exceptional values go unhandled and flow through the code.


\subsection{Lifetime of an Unhandled Exceptions}
\label{s:to-kill-a-fp}

\begin{figure}[t]
  \includegraphics[width=\columnwidth]{fig/genpropkill-outline.png}
  \caption{Gen, Prop, Kill: Lifetime of an exceptional value}
  \label{f:gpk}
\end{figure}

Unhandled exceptional values have a lifetime: they are born, or \emph{generated}, by some operation; they \emph{propagate} through other operations; and they either appear in the program output, go out of scope, or get \emph{killed} by a numeric operation.
\Cref{f:gpk} summarizes this \genpropkill{} process.
The gens and props are straightforward; see above for examples~(\cref{s:exnvalue}).
The kills often arise from numeric comparisons (\code{<}, \code{=}, etc.),
but exponents (\code{1{\string^}NaN}) and over-eager matrix
optimizations~\cite{ddghlllprr-correctness-2022} can kill exceptions as well.

To illustrate the perils of killed exceptions, consider the following two ways
of finding the maximum value in a list.
The first compares numbers with \code{<=}
while the second uses the built-in \code{max} function:

\begin{lstlisting}[language = Julia]
function max1(lst)
  max_seen = 0.0
  for x in lst
    # swap if x is not too small
    if ! (x <= max_seen)
      max_seen = x
    end
  end
  max_seen
end

function max2(lst)
  foldl(max, lst)
end
\end{lstlisting}

For lists with a \Nan{} inside, the functions can give different
results because \code{<=} kills \Nan{}s whereas \code{max}
propagates them:

\begin{lstlisting}[language = Julia]
julia> max1([1, 5, NaN, 4]) 
4.0
julia> max2([1, 5, NaN, 4]) 
NaN
\end{lstlisting}

Not only is the result from \code{max1} problematic for obscuring the fact that there was a \NaN{} in the list, the result is arguably wrong!
The result from \code{max2} at least shows that a \Nan{} was in the works, though in a realistic setting it may not be clear where the \Nan{} came from.
Both versions would thus benefit from tools that track exceptions across their lifetime.
FlowFPX can help.

\section{\FlowFPX{}}
\label{s:flowfpx}

\FlowFPX{} is a toolkit for tracking down \fp{} exceptions.
The primary tools in this paper are \FT{}, which records lifetimes
and enables fuzzing, and \CSTG{}s (more precisely, CSTGs), which visualize
the flow of exceptions.
\GPUFPX{} is a third component of \FlowFPX{} that tracks \fp{} exceptions inside GPU kernels~\cite{llsflg-hpdc-2023}.

\subsection{\FT{}}
\label{s:floattracker}

\FT{} tracks exceptional values across their \genpropkill{} lifetime
and can fuzz code for vulnerabilities by injecting a \Nan{} or \Inf{}
as the result of an operation.
\FT{} is implemented in Julia and is available on JuliaHub:

\noindent\begin{center}\noindent\!\!\url{https://juliahub.com/ui/Packages/FloatTracker/dBXig}\!\!
\end{center}

\subsubsection{Tracking Exceptional Values}
\label{s:trackingexceptionalvalues}

\begin{figure}[t]\centering
  \begin{tabular}{ccccc}
    Exn. Input? & \tblnext & Exn. Output? & = & Event       \\ \hline
    \tblN       & \tblnext &  \tblY{}     & = & {gen}  \\
    \tblY       & \tblnext &  \tblY{}     & = & {prop} \\
    \tblY       & \tblnext &  \tblN{}     & = & {kill} \\
  \end{tabular}
  \caption{How to classify operations that see exceptions}
  \label{fig:lifetime-class}
\end{figure}

\FT{} monitors \Nan{} and \Inf{} exceptions by overloading arithmetic
operations and logging key events.
When the input to an operation is exception-free but the output is
exceptional, the operation is a {gen} event~(\cref{fig:lifetime-class}).
When the input and output contain exceptions, the operation is a {prop}
event.
And when the input contains an exception but the output does not,
the operation is a {kill} event.
Put together, the log of all {gen}s, {prop}s, and {kill}s
sheds light of how various exceptions traveled across the program.
The logs also record the call context (stack trace) and the arguments to the operation as a starting point for debugging efforts.

\FT{} writes logs to three files: one for {gen} events, one for {prop}s, and one for {kill}s.
This way, discovering where a \Nan{} came from is a matter of sifting through the {gen} file.
Users can also lower the overhead of logging by turning it off for prop events.

The instrumentation works through custom \fp{} types: \code{TrackedFloat64},
\code{TrackedFloat32}, and \code{TrackedFloat16}.
Developers must opt in to \FT{} by wrapping numbers in a custom type.
From then on, tracking is automatic and extends transitively to all outputs
of tracked operations.
Multiplying a \code{Float64} value with a \code{TrackedFloat64}, for example, yields
a \code{TrackedFloat64} to continue the logging trail.


\subsubsection{Fuzzing}

Operator overloading gives \FT{} a powerful way to fuzz code from the inside out.
Each overloaded function serves as a hook where \FT{} can decide whether to observe
the operation or step in, discard the original result, and return an exception instead.
Injecting faults in a random way~\cite{hamlet1994random}, also known as fuzzing,
is a useful way to discover vulnerabilities in a large codebase.
Demmel et~al. propose essentially the same idea for BLAS and
LAPACK~\cite{ddghlllprr-correctness-2022}.

\FT{} exposes several parameters to let developers control the fuzzer:

\begin{itemize}
\item \texttt{odds::Int64} inject if \texttt{rand(odds) == 1}.
\item \texttt{n\_inject::Int64} upper bound on the number of \Nan{}s to inject.
\item \texttt{active::Bool} fuzz only when set to true.
\item \texttt{functions::Array{String}} limit fuzzing to the dynamic extent of the listed functions.
\item \texttt{libraries::Array{String}} limit fuzzing to functions from the following libraries
\end{itemize}

When fuzzing reveals an error, the next step is to craft a regression test to
guide repairs.
\FT{} therefore records the sequence of injections that it makes during a fuzzing
run and enables a replay of any recording after the fact.
Replay runs proceed deterministically so that developers can harden
their code and check that the fixes remove the error.


\subsubsection{\FT{} Internals}

\FT{} takes advantage of Julia's operator overloading to track exceptions and
fuzz for vulnerabilities.
For example, below is a variant of \code{+} that is overloaded
for \code{TrackedFloat64}.
It calls the basic \code{+} (or injects a \Nan{}) and checks for exceptions
before returning:
This lets \FT{} intercept all \fp{} operations involving \texttt{TrackedFloat} types.

\begin{lstlisting}[language = Julia]
function +(x::TrackedFloat64, y::TrackedFloat64)
  result = run_or_inject(+, x.val, y.val)
  check_error(+, result, x.val, y.val)
  TrackedFloat64(result)
end
\end{lstlisting}

Every arithmetic operation requires a similar overloading.
Thus, the implementation of \FT{} uses a metaprogramming technique
adapted from \texttt{Sherlogs.jl}~\cite{kMilanklSherlogsJl2021}
to abstract over the common patterns.
For every binary operation, the library creates an overloading similar
to the one for \code{+} above.
Unary operations and others work analogously.
This approach saved thousands of lines of code.
The implementation weighs in at 218 lines and defines 645 overloaded function;
assuming 5 lines of code per function, a handwritten version would require over 3,000 lines.


\subsection{Stack Graphs}
\label{s:cstg}

\FT{} can produce copious amounts of log files which can be challenging to sift through manually.
Coalesced stack trace graphs (CSTGs or \CSTG{}s for short) provide a way to visualize large amounts of stack traces in a compact form~\cite{humphreySystematicDebuggingMethods2014}.
This techinque pairs well with \FT{} and makes analyzing the log files easier.

\Cref{fig:cstg_demo} illustrates the construction of a \CSTG{} from a collection of stack traces.
Each trace on the left contributes nodes and edges to the graph on the right.
Repeated edges get emphasized with darker lines and larger counts.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\columnwidth]{./fig/cstg_static_diagram.png}
  \caption{From stack traces (left) to \CSTG{} (right)}
  \label{fig:cstg_demo}
\end{figure}

Reading bottom-up, a \CSTG{} based on the \emph{gen} events in a program
highlights the contexts that frequently produced exceptional values.
Using~\cref{fig:cstg_demo} as an example, \code{Frame D} produced
three exceptions, two of which arose under \code{Frame C}.
In a large program with many exceptions, \CSTG{}s offer a way to prioritize
debugging efforts: go for the heavily-trodden paths first.


\subsection{\GPUFPX{}}
\label{s:gpufpx}

Many programs offload work onto GPUs, which are no less susceptible to \fp{} exceptions than CPUs.
In fact, GPU programs are worse off because they lack exception-handling mechanisms from the CPU world~\cite{llg-soap-2022}.
Since \FT{} instruments Julia programs, it cannot help directly;
however, the companion tool \GPUFPX{} instruments GPU kernels to detect and report
\fp{} exceptions~\cite{llsflg-hpdc-2023}.
Together, \FT{} and \GPUFPX{} provide insights for accelerated programs.


\section{Case Studies}
\label{s:casestudies}

\FlowFPX{} has helped to debug exceptions and fuzz for issues in a variety
of settings, some synthetic and some realistic.
The case studies include a shallow water simulation, the
\texttt{OrdinaryDiffEq} solver, and a Bayesian inference library.

\subsection{ShallowWaters}
\label{s:sw}

\texttt{ShallowWaters.jl} simulates the flow of water over a
seabed~\cite{klowerNumberFormatsError2020,klowerPositsAlternativeFloats2019}.
The library has dozens of parameters that a scientist can experiment with.
One notable parameter is the Courant-Friedrichs-Lewy (CFL) number, which roughly describes the size of the time step to take in running the simulation.
A small CFL number makes the simulation run slowly, but accurately; a large number speeds it up but loses precision
because the system does not get enough time to propagate information.

Normal CFL values range between zero and one.
X



It is not uncommon to encounter cases where setting the CFL parameter too high results in \NaN{}s in the result.
Driving the CFL parameter low enough to excise the \NaN{}s can make the simulation too long and unwieldy to be comfortable to use.
Identifying where \NaN{}s begin to arise can help point the way to where some mathematical refinement can be used to make the simulation both fast and accurate enough for practical use.

We dialed the CFL parameter up to extraordinarily high values and we started seeing \NaN{}s in the result.
\code{ShallowWaters} detected the instability, but not before producing some bad output.

\begin{figure}[t]
  \centering
  \includegraphics[width=3in]{./fig/shallow_waters_cfl_diff.png}
  \caption{Effect of high CFL parameters: on the left, normal output. On the right: \NaN{}s cause white holes and gaps in the result.}
  \label{fig:sw_nans}
\end{figure}

The white regions in the right graph of \cref{fig:sw_nans} are regions where \NaN{}s crept into the computation and destroyed the results.
In one regard, this is not as bad as a \NaN{} kill---knowing that there are \NaN{}s in the computation means that we have a chance to fix it, whereas a \NaN{} kill might silently give us the wrong answer.
Incidentally, we know that there were no \NaN{} kills in this test all the events in our kill logs are from calling the \texttt{isnan} function---a clear sign that the program is deliberately taking action on the presence of a \NaN{}.

Finding the sources of \NaN{}s can be tricky.
We expected \NaN{}s in this case because we set the CFL parameter up so high, but tracking down the sources of \NaN{}s generally is a difficult and time-consuming problem.

\FT{} solves this problem for us by automatically tracking all sources of potential \NaN{} generation.
And in this case \texttt{ShallowWaters} makes this doubly easy:
\texttt{ShallowWaters} was designed to showcase physics simulations using variable levels of \fp{} precision, and allows you to specify a \fp{} type to use in the computation.
We simply asked it to use our \texttt{TrackedFloat32} type, and then the entire simulation ran under the supervision of FloatTracker.

\begin{lstlisting}[language = Julia]
run_model(T=TrackedFloat32,
          cfl=10, Ndays=100, nx=100, L_ratio=1,
          bc="nonperiodic",
          wind_forcing_x="double_gyre",
          topography="seamount")
\end{lstlisting}

This produced almost 17000 lines of logs in the gens file. Below is a sample stack trace from these logs: (formatted for clarity)

\begin{verbatim}
-([-Inf, -Inf])   FT/TrackedFloat.jl:106
momentum_u!       SW/rhs.jl:246
rhs_nonlinear!    SW/rhs.jl:50
rhs!              SW/rhs.jl:14 [inlined]
time_integration  SW/time_integration.jl:77
run_model         SW/run_model.jl:37
top-level
\end{verbatim}

We can see that the \NaN{} appeared as the result of $-\infty - -\infty$ (first line) and that subtraction happened in the \texttt{momentum\_u!} function on line 246 of the \texttt{rhs.jl} file (second line).
Thus, with little effort we were able to track down where the \NaN{}s were originating.

Now the question is: where did the $\infty$ come from?
We can look at the file of the $\infty$ gens where we see the following: (formatted for clarity)

\begin{verbatim}
^([-1.515f31, 2])          FT/TrackedFloat.jl:138
literal_pow()              intfuncs.jl:325
…
materialize(^)             broadcast.jl:860
top-level getproperty(...) examples/sw_nan_tf.jl:14
…
\end{verbatim}

It looks like the $-\infty$ came from $-1.515e31^2$---no wonder a Float32 type couldn't handle something that large.
Now we have some concrete values to work with: instead of wondering where an opaque \Inf{} or a \NaN{} came from, we have \emph{specific} values that a domain expert can use to diagnose the problem.

\subsubsection{CSTGs Help Us Get a Bigger Picture}

Running FloatTracker can produce a lot of logs.
To get a quick overview of the most common paths to problems, we can use CSTG to get an overview of what stack frames appear the most often.

We can produce a CSTG of both the \Inf{} as well as the \NaN{} logs.
\Cref{fig:sw_nan_cstg} and \cref{fig:sw_inf_cstg} show what the two graphs look like.\footnote{As with the call stack logs, these have been edited for clarity. We only remove a few boxes in between—mostly due to space constraints in this paper.}


\begin{figure}[t]
  \centering
  \includegraphics[width=0.96\columnwidth]{fig/sw_nan_cstg_clean.png}
  \caption{CSTG of \NaN{} generation logs from ShallowWaters.}
  \label{fig:sw_nan_cstg}
\end{figure}

% \begin{figure}[t]
%   \centering
%   \includegraphics[width=3in]{fig/sw_inf_cstg_clean.png}
%   \caption{CSTG of \Inf{} generation logs from the same run as~\cref{fig:sw_nan_cstg}.}
%   \label{fig:sw_inf_cstg}
% \end{figure}

We can see in \cref{fig:sw_nan_cstg} that a thick line goes from the top-level call down to a call to \texttt{+} goes down the right side of the graph.
This indicates that the majority of the flows took this path.
That means we might be able to fix the majority of our problems by inspecting that particular flow.
\Cref{fig:sw_inf_cstg} shows us that all but two flows started with a call to \texttt{\^}---a promising place to start looking for improvements.

\subsubsection{CSTG Diffing}

Another one of CSTGs abilities is \emph{graph diffing}.
We took the \FT{} logs from running ShallowWaters and split the logs at the 10\% mark.
We used CSTG to diff the flow graphs between the first 10\% of the logs and the remaining 90\%.
The diff can be seen in \cref{fig:cstg_diff_demo}.

\begin{figure}[t]
  \centering
  \includegraphics[width=3in]{./fig/cstg_diff_pretty.png}
  \caption{Diff between the early and latter stages of ShallowWaters}
  \label{fig:cstg_diff_demo}
\end{figure}

The green lines indicate flows that were \emph{new} in the latter 90\% of the logs.
The red lines indicate flows that were \emph{only in} the first 10\% of the logs.
What this means depends on the particular program; a domain expert can use these clues to e.g. find where instability started in the first part of the program, and where that instability got reinforced later on.
In this case, we can see that \texttt{momentum\_u!} only showed up in the beginning of the logs---we might look there for ways to prevent instability from beginning.

\subsection{OrdinaryDiffEq}
\label{s:ode}

To exercise the fuzzing abilities of \FT{}, we tried fuzzing \texttt{NBodySimulator}\footnote{\url{https://github.com/SciML/NBodySimulator.jl}} from the SciML team, which simulates the gravitational interactions between two or more massive bodies.
However, when we used \FT{}, we got no \fp{} operations.
We discovered that \texttt{NBodySimulator} merely sets up the system of equations to solve, then hands all the work of running the simulation off to the \texttt{OrdinaryDiffEq}\footnote{\url{https://github.com/SciML/OrdinaryDiffEq.jl}} library from the same team.

We configured \FT{} to inject a single \NaN{} randomly within the scope of the \texttt{NBodySimulator} and \texttt{OrdinaryDiffEq} libraries.
We found a run where something curious happened: the library reported that it had detected a \NaN{} and would then exit.
However, after printing that message, the program went into an infinite loop.

Using CSTGs to guide our search, we found a \NaN{} kill that manifested repeatedly in the logs.
The stack traces for that kill originated from inside the \texttt{solve.jl} file in the \texttt{OrdinaryDiffEq} library.

\begin{verbatim}
<([NaN, 3.0e6])  at FT/TrackedFloat.jl:193
solve!           at ODE/solve.jl:515
…
\end{verbatim}

The relevant part of \texttt{solve.jl} looks like this:

% file here: ~/Research/ode_debug/dev/OrdinaryDiffEq/src/solve.jl
% see line 514

\begin{lstlisting}[language = Julia]
while !isempty(time_stops)
  while tdir * t < first(time_stops)
    # do integration work
    # pop_off(time_stops)
  end
end
\end{lstlisting}

The problem here is on line 2 when \texttt{tdir} is \NaN{}: multiplication propagates \NaN{}s, and comparison kills it, so the condition on the inner \texttt{while} loop is \emph{always} false.
No work got done in the inner loop, and so the size of the \texttt{time\_stops} vector never decreases.

Our kill logs led us right to this line and let us know which of the arguments to \texttt{<} was a \NaN{}.
This is a perfect example of how \NaN{} kills can influence control flow to go awry.
In this case, the problem was apparent besides what our logs told us and it manifested as an infinite loop.
More dangerous cases can occur when the influence of a bad comparison is not as readily observable.
In any case, \FT{} can help monitor for kills and help fuzz to find kills before they arise in production.

We were able to use the injection recording to reproduce the bug in the GitHub issue that we opened.\footnote{\url{https://github.com/SciML/OrdinaryDiffEq.jl/issues/1939}}

\subsection{Finch}
\label{s:finch}

Finch is a domain-specific language for specifying
PDEs~\cite{heislerFinchDomainSpecific2022}.\footnote{Not to be confused
with the Finch loop optimizer~\cite{adka-cgo-2023}.}
In the spirit of FEniCS~\cite{fenics} and related
tools~\cite{freefem,openfoam,dune,firedrake},
Finch helps scientists quickly convert math into code.
What sets Finch apart is its flexibility.
It supports multiple discretization methods (finite element and finite
volume) and multiple backends (Julia, \CPP{}, \Dendro{}~\cite{dendro}).
Furthermore it strives to output code that humans can easily fine-tune.

Fuzzing with \FT{} revealed two places where Finch needed
protection against user input.
The first was when reading an input mesh.\footnote{\urlaccess{https://github.com/paralab/Finch/issues/16}{2023-06-06}}
A \NaN{} injected in the mesh led to a crash further on:

\begin{verbatim}
  BoundsError: attempt to access 1-element
   Vector{Int64} at index [2]
\end{verbatim}

Defensive programming solves the issue.
The second place was in setting bounds for the
solver.\footnote{\urlaccess{https://github.com/paralab/Finch/issues/17}{2023-06-06}}
Here, a \NaN{} could leave bounds uninitialized, leading to a bounds error.
Additionally, \FT{} and \CSTG{}s have been useful for identifying \NaN{}s that
appear in unstable systems.
%% advection2d, high cfl and high T (time) led to NaN during simulation

\subsection{\GPUFPX{}: Oceananigans}
\label{s:ocean}

Oceananigans~\cite{OceananigansJOSS} is simulation package for incompressible
fluid dynamics that can generate code for Nvidia GPUs.
For example, the following program (from the project readme) simulates turbulance:

\begin{lstlisting}[language = Julia]
using Oceananigans
grid = RectilinearGrid(GPU(),
  size=(128, 128), x=(0, 2π), y=(0, 2π),
  topology=(Periodic, Periodic, Flat))
model = NonhydrostaticModel(; grid,
  advection=WENO())
ϵ(x, y, z) = 2rand() - 1
set!(model, u=ϵ, v=ϵ)
simulation = Simulation(model;
  Δt=0.01, stop_time=4)
run!(simulation)
\end{lstlisting}

\GPUFPX{} provides detailed feedback on this program.
The output in~\cref{f:gpufpx} shows that 21 kernels
appear and generate six floating-point exceptions.
There are three \NaN{}s, one \Inf{}, and two division
by zero errors.
The report is a starting point for further investigation
of the reliability of the example.
%% TODO exactly how?

\begin{figure}[t]\centering
  \begin{tabular}[t]{ll}
    \begin{tabular}[t]{lr}
      \zerocode{-{}- FP64 Operations -{}-} \\
      \code{Total NaN:} & \code{2} \\
      \code{Total INF:} & \code{1} \\
      \code{Total subnormal:} & \code{0} \\
      \code{Total div0:} & \code{2} \\
    \end{tabular}
    &
    \begin{tabular}[t]{lr}
      \zerocode{-{}- FP32 Operations -{}-} \\
      \code{Total NaN:} & \code{1} \\
      \code{Total INF:} & \code{0} \\
      \code{Total subnormal:} & \code{0} \\
      \code{Total div0:} & \code{0} \\
    \end{tabular}
  \end{tabular}
  \begin{tabular}{lr}
    \zerocode{-{}- Other Stats -{}-} \\
    \code{Kernels:} & \code{21}
  \end{tabular}

  \caption{Example \GPUFPX{} output}
  \label{f:gpufpx}
\end{figure}

\subsection{RxInfer: No Help Needed}
\label{s:safari}

\FT{} has proven to be useful for more than its creators---we discovered an open issue in the \code{RxInfer.jl} library with an issue revolving around \NaN{} detection.\footnote{\url{https://github.com/biaslab/RxInfer.jl/issues/116}}
Even though we were unable to provide hands-on guidance as the code in question was proprietary, the authors of \code{RxInfer.jl} were able use \FT{} themselves, and within a day they tracked down the location of a \NaN{} gen.

\section{Related Work}
\label{s:related}

\subsection{Floating-Point Error Analysis}

Demmel et al.\cite{ddghlllprr-correctness-2022} examine \fp{} exceptional value handling in the BLAS and LAPACK libraries and propose solutions to inconsistencies.
They describe a proposal to pack numeric codes into an \texttt{INFO\_ARRAY} that mirrors our gen-prop-kill framework.
They also suggest a fuzzing technique that we realize in \FT{}:
instead of fuzzing the \emph{inputs} to a program, we fuzz by randomly injecting exceptional values at \emph{any} point where there is an arithmetic operation. Demmel suggests that this approach is useful since any \fp{} operation could lead to an exceptional value if the inputs are in dangerous ranges.

Toronto and McCarthy\cite{torontoPracticallyAccurateFloatingPoint2014} develop a methodology for assessing where arithmetic operations are liable to magnify \fp{} error.
They include error visualization and work on how to avoid error-magnifying ``badlands''.
They focus on rewriting arithmetic expressions to avoid error which could lead to exceptional values, rather than on the exceptional values themselves.

In a similar vein, Herbie\cite{panchekhaAutomaticallyImprovingAccuracy2015} is a tool for automatically rewriting arithmetic expressions to reduce \fp{} error.
\FT{} tracks down exceptional \fp{} values; once the location of a gen is found, Herbie could be employed to rewrite the arithmetic expression, if \fp{} error is the cause of the exceptional value.
The Odyssey\cite{misbackOdysseyInteractiveWorkbench2023} workbench provides an interactive interface to Herbie.

\subsection{Diagnosing floating-point exceptions}

The Julia library \texttt{Sherlogs}~\cite{kMilanklSherlogsJl2021} inspired the use of a custom number type to intercept operations on a number.
In contrast to \FT{} which monitors for exceptional values and logs stack traces at interesting points in their lifetime, \texttt{Sherlogs} tracks and reports the range of values seen over the course of a computation.
This is intended to provide insight into whether or not a library could tolerate a lower-precision \fp{} format.

% TODO: make sure that what I said about what FPSpy can track is true.
FPSpy~\cite{dindaSpyingFloatingPoint2020} is an \texttt{LD\_PRELOAD} shared library that works on unmodified x86 binaries.
It can monitor a program during execution for any \fp{} arithmetic issues, such as division by zero, denormalization, underflow, and overflow.
\FT{} in contrast focuses on the lifetime of exceptional values; \FT{} can notice when a \NaN{} gets killed, for instance, while that is not an event that FPSpy appears to be able to track.
FPSpy has the advantage of being lightweight enough to run on production code for certain loads.

\subsection{Stack Trace Graphs}

CSTG~\cite{humphreySystematicDebuggingMethods2014} is built on the work of and related to the STAT~\cite{arnoldStackTraceAnalysis2007} tool developed by Laurence Livermore National Laboratory.
STAT is a tool for collecting, analyzing, and visualizing stack traces from thousands of concurrent processes, and is designed to highlight anomalies quickly.
It produces visualizations similar to those of CSTG, thought CSTG offers more compact views.

\subsection{Floating-Point Exceptions on the GPU}

FPChecker~\cite{l-ase-2019} is a tool to report \fp{} exceptions occurring on the GPU.
FPChecker relies on LLVM-level instrumentation of GPU kernels, and so cannot run on the plethora of closed-source GPU kernels in usage today.

BinFPE~\cite{llg-soap-2022} is another tool in the same space;
BinFPE performs SASS-level analysis of GPU kernels, but is limited in that it is slow and does not catch errors that alter control flow.
The latter deficiency is particularly worrisome, as we have seen, silent \NaN{} kills can invalidate results without the user noticing.

\GPUFPX{}~\cite{llsflg-hpdc-2023} improves on the work of FPChecker and BinFPE by being more performant and catching a wider set of errors, including those that alter control flow.
\GPUFPX{} is a shared library that, like FPSpy uses \texttt{LD\_PRELOAD} to work on unmodified binaries.
\GPUFPX{} runs on CUDA cores from NVIDIA and reports total numbers of exceptional values.
Like \FT{}, \GPUFPX{} can catch \NaN{} gens and kills, but it does this on the GPU where \FT{} doesn't apply.
Despite these improvements, \GPUFPX{} is limited by the closed-source nature of common GPU cores, and cannot report at the rich level of source detail that \FT{} can.

Work is ongoing to use \GPUFPX{} and \FT{} in tandem.

% Error analysis, typical answer.
% Difficult.
% CITE

% % Herbie, improving accuracy automatically.
% % ParetoHerbie

% %% http://eprints.maths.manchester.ac.uk/2873/1/fami22.pdf
% %% https://drive.google.com/drive/folders/1HkgMpxi6hsqLSZj9tSnuCxnFExPPjmvx?usp=sharing
% %% https://docs.google.com/presentation/d/1ueqzb5QY9YHmtY2DfY_hpN9oufSOcXErLWsJOZQxgzo/edit?usp=sharing
% %% https://ieeexplore.ieee.org/document/8916392
% %% https://link.springer.com/chapter/10.1007/978-3-319-73721-8_24

% FPChecker, " considers CPU OpenMP and MPI codes, again using LLVM
% instrumentation"~\cite{ltlg-iiswc-2022}
% % FPChecker has a nice table of tools; some already mentioned here

% 6-8,24,25
% Arnab Das scalable yet rigorous
% Marc Daumas Certification of Bounds Expres
% David Delmas Towards an Industrial Use of
% Alexey Solovyev FPTaylor Results table
% Titolo absint

% GPU-FPX state of art, companion project~\cite{llsflg-hpdc-2023}.
% Latest in line of work.
% BinFPE exn checking, slower than GPU-FPX, 
% \cite{llg-soap-2022}.
% FPChecker, early pioneer, fpx in gpus, llvm-level instrumentation
% if compiled with Clang, but most gpus use closed NVCC compiler~\cite{l-ase-2019}.

\section{Discussion}
\label{s:discussion}
% future work

FILL Consistent exception handling.

https://github.com/JuliaLang/julia/issues/48523

Ashton: @Ben we simply propagate whatever we got from the operation. If
Julia's behavior around an operator change, that should be preserved even
when using FloatTracker

Ben: @Ashton tell the JuliaCon readers not just me!


\subsection{Performance}
\label{s:discussion-performance}

% TODO: citations!!!!
% TODO: real numbers!!!
\FT{} incurs significant overhead on the order of 100x slower than a non-instrumented run of the same program.
To put this number into context, Valgrind runs with a similar level of slowdown.

In addition to the cost incurred by intercepting \fp{} operations, gathering stack traces is expensive---we measured a significant slowdown on the order of 10x relative to a non-logging setup of \FT{}.
We recommend that users of \FT{} make use of the \texttt{maxLogs} and \texttt{exclude\_stacktrace} configuration options to limit the number and kind of logs gathered, and thereby reduce the number of calls to \texttt{stacktrace()}.

When injection is turned on we defer the stack checks as late as we can.
Once the fuzzer runs out of \NaN{}s, it effectively turns off, so the rest of the fuzzing session proceeds much more quickly.
That said, gathering stack traces still incurs a heavy overhead during logging when interesting events occur;
we recommend limiting the number and kinds of events logged for optimal performance.

\subsection{Tracking More than \NaN{}s and \Inf{}s}

FloatTracker is capable of monitoring all sorts of events in a \fp{} value's lifetime---not just a value going to \NaN{} or \Inf{}.
For example, \FT{} could be made to monitor extreme values: in some circumstances it would be useful to notice when a value started climbing above or falling below a certain threshold.

We spent most of the time engineering and testing \NaN{} tracking and injection.
Adding \Inf{} tracking took a few hours.
Adding other values of interest presents no fundamental difficulties.

\subsection{Enhanced Fuzzing}

While fuzzing is useful for discovering issues, its success rate
is low because \emph{every} \fp{} operation is a candidate
for injection.
Even operations that are already well-defended against \NaN{}s are candidates.
\FT{} could use two sorts of tools for improving injection.
First, fine-grained control to let users decide where not to inject.
Second, tools for understanding the context of an injection point
after the fact.
Program slicing is especially relevant to the latter point and effectively
what we did by hand when fuzzing Finch (\cref{s:finch}).
For each operation, an expert needs to study the values that feed into it to
decide whether they are protected or not.

%% TODO example, start here at glbvertex https://github.com/paralab/Finch/blob/master/src/grid.jl#L360

\subsection{Tracking Exceptions in External Libraries}

\FT{}'s scope is limited to Julia code: it cannot track the lifetime of exceptional values that are born, live, or die in external libraries, such as C programs.
One approach would be to create an API for \FT{} so that programs using these external libraries could leverage \FT{}'s tooling to monitor the interface between Julia and e.g. external C programs.

\subsection{Future Work}

\FlowFPX{} is a growing project and we welcome feedback from domain experts
on how to best suit their workflow.
If you try any of our tools, please send us comments, suggestions, and bug reports via the tools' repositories on GitHub.

\section{Acknowledgments}

We would like to thank Alex Larsen and Rob Durst for their help with reading drafts of the paper and feedback on the presentation.
We would also like to thank the developers of \code{RxInfer.jl} for feedback on \FlowFPX{}.
Finally, many thanks to Milan Klöwer, the author of the \texttt{Sherlogs} library, for inspiration on the architecture of \FT{}.

\input{bib.tex}

\end{document}

% Below is some Emacs-specific stuff to help me (Ashton) write this paper. If
% you're using Emacs, you should try using the new jinx package for
% spell-checking!

% Local Variables:
% jinx-local-words: "BinFPE CFL CSTG's CSTGs Courant Demmel FPChecker Friedrichs Herbie JuliaHub Klöwer Lewy OrdinaryDiffEq RxInfer ShallowWaters Sherlogs TrackedFloat isnan"
% citar-bibliography: ("./ref.bib")
% End:
